{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4314a415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2208\n",
      "2208\n",
      "14034\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from skimage.io import imread, imshow\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import normalize,StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "\n",
    "#Directory and Categories for classification\n",
    "dir= '/home/ameeth/WC/'\n",
    "\n",
    "categories=['buildings','forest','glacier','mountain','sea','street']\n",
    "target_names = ['buildings','forest','glacier','mountain','sea','street']\n",
    "\n",
    "#Opening feature pickle files\n",
    "\n",
    "pick_in=open('denseNet161_intel_train.pickle','rb')\n",
    "data1=pickle.load(pick_in)\n",
    "pick_in.close()\n",
    "\n",
    "pick_in=open('denseNet161_intel_test.pickle','rb')\n",
    "data2=pickle.load(pick_in)\n",
    "pick_in.close()\n",
    "\n",
    "#Splitting Data into features and labels and normalizing data\n",
    "random.shuffle(data1)\n",
    "random.shuffle(data2)\n",
    "features_train=[]\n",
    "labels_train=[]\n",
    "features_test=[]\n",
    "labels_test=[]\n",
    "for feature,label in data1:\n",
    "\tfeatures_train.append(feature)\n",
    "\tlabels_train.append(label)\n",
    "\n",
    "for feature,label in data2:\n",
    "  features_test.append(feature)\n",
    "  labels_test.append(label)\n",
    "\n",
    "print(len(features_train[0]))\n",
    "print(len(features_test[0]))\n",
    "\n",
    "print(len(labels_train))\n",
    "print(len(labels_test))\n",
    "\n",
    "\n",
    "df1=pd.DataFrame(features_train)\n",
    "df2=pd.DataFrame(features_test)\n",
    "nor1=normalize(df1)\n",
    "nor2=normalize(df2)\n",
    "xtrain=pd.DataFrame(nor1)\n",
    "xtest=pd.DataFrame(nor2)\n",
    "#Removing zero value columns\n",
    "xtrain = xtrain.loc[:, (xtrain != 0).any(axis=0)]\n",
    "xtest = xtest.loc[:, (xtest != 0).any(axis=0)]\n",
    "ytrain=labels_train\n",
    "ytest=labels_test\n",
    "'''\n",
    "from sklearn.feature_selection import SelectPercentile as SP\n",
    "selector1 = SP(percentile=50) # select features with top 50% MI scores\n",
    "\n",
    "selector1.fit(norm1,labels)\n",
    "X = selector1.transform(norm1)\n",
    "'''\n",
    "'''\n",
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=0.95)\n",
    "norm=pca.fit_transform(norm1)\n",
    "\n",
    "#xtrain,xtest, ytrain,ytest=train_test_split(norm,labels,test_size=0.2,random_state=42)\n",
    "xtrain,xtest, ytrain,ytest=train_test_split(norm,labels,test_size=0.25,random_state=42)\n",
    "accuracies={}\n",
    "mean_accuracies={}\n",
    "'''\n",
    "##########################################################################################################################################################################\n",
    "#SVC \n",
    "\n",
    "#import time\n",
    "#start=time.time()\n",
    "from sklearn.svm import SVC\n",
    "model=SVC(C=1,kernel='linear',gamma='auto')\n",
    "model.fit(xtrain,ytrain)\n",
    "svc_prediction=model.predict(xtest)\n",
    "accuracy1=model.score(xtest,ytest)\n",
    "accuracy_train1=model.score(xtrain,ytrain)\n",
    "\n",
    "print('Training accuracy', accuracy_train1)\n",
    "\n",
    "print('Test Accuracy',accuracy1)\n",
    "print('Prediction is: ',categories[svc_prediction[0]])\n",
    "cm=confusion_matrix(ytest,svc_prediction)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b58e34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
